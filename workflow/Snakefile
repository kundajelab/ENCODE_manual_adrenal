import os
import json
from snakemake.utils import min_version

min_version("6.6.1")

configfile: 
    "config/config.yaml"

with open("config/samples.tsv") as sample_file:
    h = sample_file.readline().rstrip('\n').split('\t')
    exp_ind = h.index("Experiment")
    rep_ind = h.index("Replicate")
    assay_ind = h.index("Assay")
    samples_atac = []
    samples_rna = []
    for line in sample_file:
        if line.startswith("#"):
            continue
        entries = line.rstrip('\n').split('\t')
        exp = entries[exp_ind]
        rep = entries[rep_ind]
        assay = entries[assay_ind]
        if assay == "ATAC":
            samples_atac.append(f"{exp}-{rep}")
        elif assay == "RNA":
            samples_rna.append(f"{exp}-{rep}")

with open("config/samples_rna.tsv") as sample_file:
    h = sample_file.readline().rstrip('\n').split('\t')
    exp_ind = h.index("Experiment")
    rep_ind = h.index("Replicate")
    samples_rna = []
    for line in sample_file:
        if line.startswith("#"):
            continue
        entries = line.rstrip('\n').split('\t')
        exp = entries[exp_ind]
        rep = entries[rep_ind]
        samples_rna.append(f"{exp}-{rep}")

workdir: 
    config['workdir']

max_threads = config["max_threads_per_rule"]

def script_path(script_name):
    return str(workflow.source_path(script_name))

include:
    "rules/atac.smk"
include:
    "rules/rna.smk"

rule all:
    """
    Generate all outputs (default)
    """
    input: 
        # expand("results/{sample}/atac/archr_clustered", sample=samples_atac),
        # expand("results/{sample}/rna/seurat_clustered/proj.rds", sample=samples_rna)
        "results_merged/rna/seurat_cluster_rna/proj.rds"

rule query_fragments:
    """
    Query ENCODE portal for fragments URL
    """
    output:
        "results/{sample}/fetch/fragments_url.txt"
    params:
        experiment = lambda w: w.sample.split("-")[0],
        replicate = lambda w: w.sample.split("-")[1],
        dcc_mode = config["dcc_mode"],
        dcc_api_key = os.environ["DCC_API_KEY"], 
        dcc_secret_key = os.environ["DCC_SECRET_KEY"]
    log:
        directory("logs/{sample}/query_fragments")
    conda:
        "envs/fetch.yaml"
    script:
        "scripts/get_download_url.py"

rule download_fragments:
    """
    Download fragments tarball
    """
    input:
        "results/{sample}/fetch/fragments_url.txt"
    output:
        "results/{sample}/fetch/fragments.tar.gz"
    params:
        usr = os.environ["DCC_API_KEY"],
        pwd = os.environ["DCC_SECRET_KEY"]
    conda:
        "envs/fetch.yaml"
    shell:
        # "curl --no-progress-meter -L -u {params.usr}:{params.pwd} $(< {input}) > {output}"
        "curl --no-progress-meter -L $(< {input}) > {output}"

rule extract_fragments:
    """
    Extract fragments file from tarball
    """
    input:
        "results/{sample}/fetch/fragments.tar.gz"
    output:
        directory("results/{sample}/fetch/fragments_extracted")
    conda:
        "envs/fetch.yaml"
    shell:
        "mkdir -p {output}; "
        "tar -xzf {input} --transform='s/.*\///' -C {output}"

rule move_fragments:
    """
    Move fragments data to final location
    """
    input:
        "results/{sample}/fetch/fragments_extracted"
    output:
        frag = "results/{sample}/fetch/fragments.tsv.gz",
        frag_ind = "results/{sample}/fetch/fragments.tsv.gz.tbi"
    conda:
        "envs/fetch.yaml"
    shell:
        "cp {input}/fragments.tsv.gz {output.frag}; "
        "cp {input}/fragments.tsv.gz.tbi {output.frag_ind};"

rule query_expression:
    """
    Query ENCODE portal for gene expression matrix URL
    """
    output:
        "results/{sample}/fetch/expression_url.txt"
    params:
        experiment = lambda w: w.sample.split("-")[0],
        replicate = lambda w: w.sample.split("-")[1],
        dcc_mode = config["dcc_mode"],
        dcc_api_key = os.environ["DCC_API_KEY"], 
        dcc_secret_key = os.environ["DCC_SECRET_KEY"]
    log:
        directory("logs/{sample}/query_fragments")
    conda:
        "envs/fetch.yaml"
    script:
        "scripts/get_expression_url.py"

rule download_expression:
    """
    Download expression tarball
    """
    input:
        "results/{sample}/fetch/expression_url.txt"
    output:
        "results/{sample}/fetch/expression.tar.gz"
    params:
        usr = os.environ["DCC_API_KEY"],
        pwd = os.environ["DCC_SECRET_KEY"]
    conda:
        "envs/fetch.yaml"
    shell:
        # "curl --no-progress-meter -L -u {params.usr}:{params.pwd} $(< {input}) > {output}"
        "curl --no-progress-meter -L $(< {input}) > {output}"

rule extract_expression:
    """
    Extract expression data from tarball
    """
    input:
        "results/{sample}/fetch/expression.tar.gz"
    output:
        directory("results/{sample}/fetch/expression_extracted")
    conda:
        "envs/fetch.yaml"
    shell:
        "mkdir -p {output}; "
        "tar -xzf {input} --transform='s/.*\///' -C {output}"

rule move_expression:
    """
    Move expression data files to final location
    """
    input:
        "results/{sample}/fetch/expression_extracted"
    output:
        matrix = "results/{sample}/fetch/matrix.mtx",
        features = "results/{sample}/fetch/features.tsv",
        barcodes = "results/{sample}/fetch/barcodes.tsv",
    conda:
        "envs/fetch.yaml"
    shell:
        "cp {input}/matrix.mtx {output.matrix}; "
        "cp {input}/features.tsv {output.features}; "
        "cp {input}/barcodes.tsv {output.barcodes};"

rule download_rna_ref_counts:
    """
    Download reference expression tarball
    """
    output:
        "reference/fetch/expression.tar.gz"
    params:
        url = config["rna_ref_counts"]
    conda:
        "envs/fetch.yaml"
    shell:
        "curl --no-progress-meter -L {params.url} > {output}"

rule extract_rna_ref_counts:
    """
    Extract reference expression data from tarball
    """
    input:
        "reference/fetch/expression.tar.gz"
    output:
        directory("reference/fetch/expression_extracted")
    conda:
        "envs/fetch.yaml"
    shell:
        "mkdir -p {output}; "
        "tar -xzf {input} --transform='s/.*\///' -C {output}"

rule move_rna_ref_counts:
    """
    Move reference expression data files to final location
    """
    input:
        "results/{sample}/fetch/expression_extracted"
    output:
        matrix = "results/{sample}/fetch/matrix.mtx",
        features = "results/{sample}/fetch/features.tsv",
        barcodes = "results/{sample}/fetch/barcodes.tsv",
    conda:
        "envs/fetch.yaml"
    shell:
        "cp {input}/matrix.mtx {output.matrix}; "
        "cp {input}/features.tsv {output.features}; "
        "cp {input}/barcodes.tsv {output.barcodes};"

rule download_rna_ref_metadata:
    """
    Download reference metadata
    """
    output:
        "reference/fetch/metadata.tsv"
    params:
        url = config["rna_ref_metadata"]
    conda:
        "envs/fetch.yaml"
    shell:
        "curl --no-progress-meter -L {params.url} > {output}"